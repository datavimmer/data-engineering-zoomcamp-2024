{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d298312-d2cb-4bba-a2ce-2f2f2e8d321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/spark')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"MySparkApp\").getOrCreate()\n",
    "print(spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83a85ef8-1565-4a98-a038-4c73b449bfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/01 17:05:07 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"FHVDataProcessing\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef5c046-77c5-467e-85f4-49e20f1daad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"dispatching_base_num\", StringType(), True),\n",
    "    StructField(\"pickup_datetime\", TimestampType(), True),\n",
    "    StructField(\"dropOff_datetime\", TimestampType(), True),\n",
    "    StructField(\"PUlocationID\", IntegerType(), True),\n",
    "    StructField(\"DOlocationID\", IntegerType(), True),\n",
    "    StructField(\"SR_Flag\", IntegerType(), True),\n",
    "    StructField(\"Affiliated_base_number\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cffb41dd-e7b6-4c28-9e4e-a8476d8c082b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dispatching_base_num: string, pickup_datetime: timestamp, dropOff_datetime: timestamp, PUlocationID: int, DOlocationID: int, SR_Flag: int, Affiliated_base_number: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('fhv_tripdata_2019-10.csv.gz', header=True, schema=schema)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc9826f7-e8fa-4ee0-80f6-baa52e4b6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repartitioned = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cac0000d-7707-4fdc-8d9c-64ff9bce8bb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Q2:\n",
    "df_repartitioned.write.parquet('fhv_tripdata_2019-10_partitioned.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e95f8bf-2495-4a42-abec-504ab69e2fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Question 3:\n",
    "\n",
    "#Count records\n",
    "\n",
    "#How many taxi trips were there on the 15th of October?\n",
    "from pyspark.sql.functions import col, dayofmonth, month, year\n",
    "\n",
    "df_filtered = df.filter(\n",
    "    (dayofmonth(col(\"pickup_datetime\")) == 15) &\n",
    "    (month(col(\"pickup_datetime\")) == 10) &\n",
    "    (year(col(\"pickup_datetime\")) == 2019)\n",
    ")\n",
    "\n",
    "trip_count = df_filtered.count()\n",
    "print(trip_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9822cee-e262-4663-a2ca-4525badbca07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01fcb39f-d572-440a-8f7e-79b50b3c0ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00009|2019-10-15 00:08:00|2019-10-15 00:13:00|         264|         264|   NULL|                B00009|\n",
      "|              B00009|2019-10-15 00:13:00|2019-10-15 00:41:00|         264|         264|   NULL|                B00009|\n",
      "|              B00013|2019-10-15 00:57:07|2019-10-15 00:57:49|         264|         264|   NULL|                B00013|\n",
      "|              B00013|2019-10-15 00:57:54|2019-10-15 00:58:36|         264|         264|   NULL|                B00013|\n",
      "|              B00013|2019-10-15 00:58:50|2019-10-15 00:59:52|         264|         264|   NULL|                B00013|\n",
      "|              B00013|2019-10-15 00:03:05|2019-10-15 00:08:14|         264|         264|   NULL|                B00013|\n",
      "|              B00013|2019-10-15 00:32:15|2019-10-15 00:35:55|         264|         264|   NULL|                B00013|\n",
      "|              B00013|2019-10-15 00:32:20|2019-10-15 00:36:52|         264|         264|   NULL|                B00013|\n",
      "|              B00014|2019-10-15 00:21:16|2019-10-15 00:34:51|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-15 00:29:22|2019-10-15 00:33:45|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-15 00:31:53|2019-10-15 00:36:19|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-15 00:37:31|2019-10-15 01:05:21|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-15 00:13:57|2019-10-15 00:42:07|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-15 00:59:16|2019-10-15 01:50:56|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-15 00:13:57|2019-10-15 00:44:35|         264|         264|   NULL|                B00014|\n",
      "|     B00021         |2019-10-15 00:43:01|2019-10-15 00:55:15|          82|         129|   NULL|       B00021         |\n",
      "|              B00037|2019-10-15 00:28:53|2019-10-15 00:32:30|         264|          85|   NULL|                B00037|\n",
      "|              B00037|2019-10-15 00:40:19|2019-10-15 00:44:58|         264|          85|   NULL|                B00037|\n",
      "|              B00037|2019-10-15 00:02:40|2019-10-15 00:09:13|         264|         188|   NULL|                B00037|\n",
      "|              B00037|2019-10-15 00:16:37|2019-10-15 00:19:11|         264|          72|   NULL|                B00037|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0be70cf-9bda-4231-9c11-33550b0dadb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|day_of_year|longest_trip_hours|\n",
      "+-----------+------------------+\n",
      "|        301|          631152.5|\n",
      "|        284|          631152.5|\n",
      "|        304| 87672.44083333333|\n",
      "|        274| 70128.02805555555|\n",
      "|        290|            8794.0|\n",
      "|        299| 8784.166666666666|\n",
      "|        303|1464.5344444444445|\n",
      "|        298|1056.8266666666666|\n",
      "|        275| 769.2313888888889|\n",
      "|        296| 745.6166666666667|\n",
      "|        276|          745.3825|\n",
      "|        277| 744.6166666666667|\n",
      "|        280| 744.1666666666666|\n",
      "|        278| 697.1808333333333|\n",
      "|        279| 674.0077777777777|\n",
      "|        281| 625.0822222222222|\n",
      "|        289| 604.0666666666667|\n",
      "|        282| 601.3102777777777|\n",
      "|        283| 577.3888888888889|\n",
      "|        285|          528.9125|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Question 4:\n",
    "\n",
    "#Longest trip for each day\n",
    "\n",
    "#What is the length of the longest trip in the dataset in hours?\n",
    "\n",
    "from pyspark.sql.functions import col, dayofyear, max, hour, datediff, to_date\n",
    "\n",
    "df_enriched = df.withColumn(\"trip_duration_hours\", (col(\"dropOff_datetime\").cast(\"long\") - col(\"pickup_datetime\").cast(\"long\")) / 3600)\n",
    "\n",
    "# Group by the day of the year and find the maximum trip duration for each day\n",
    "df_grouped = df_enriched.groupBy(dayofyear(\"pickup_datetime\").alias(\"day_of_year\")).agg(max(\"trip_duration_hours\").alias(\"longest_trip_hours\"))\n",
    "\n",
    "# Show the results\n",
    "df_grouped.orderBy(col(\"longest_trip_hours\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae96e867-d418-4d7f-b36a-0a03d2e24b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_schema = StructType([\n",
    "    StructField(\"LocationID\", IntegerType(), True),\n",
    "    StructField(\"Borough\", StringType(), True),\n",
    "    StructField(\"Zone\", StringType(), True),\n",
    "    StructField(\"service_zone\", StringType(), True)\n",
    "])\n",
    "\n",
    "zone_df = spark.read.csv('taxi_zone_lookup.csv', header=True, schema=zone_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56ba96e5-392f-437f-b7f1-d5330610c948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The least frequent pickup location zone is: Jamaica Bay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Join the FHV trip data with the taxi zone lookup data\n",
    "joined_df = df.join(zone_df, df.PUlocationID == zone_df.LocationID)\n",
    "\n",
    "# Group by the Zone and count the occurrences\n",
    "zone_counts = joined_df.groupBy(\"Zone\").count()\n",
    "\n",
    "# Find the least frequent pickup location zone\n",
    "least_freq_zone = zone_counts.orderBy(\"count\").first()\n",
    "\n",
    "print(f\"The least frequent pickup location zone is: {least_freq_zone['Zone']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "932f50e6-bb77-4cc6-bb10-c8b89b0f4b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                Zone|count|\n",
      "+--------------------+-----+\n",
      "|         Jamaica Bay|    1|\n",
      "|Governor's Island...|    2|\n",
      "| Green-Wood Cemetery|    5|\n",
      "|       Broad Channel|    8|\n",
      "|     Highbridge Park|   14|\n",
      "|        Battery Park|   15|\n",
      "|Saint Michaels Ce...|   23|\n",
      "|Breezy Point/Fort...|   25|\n",
      "|Marine Park/Floyd...|   26|\n",
      "|        Astoria Park|   29|\n",
      "|    Inwood Hill Park|   39|\n",
      "|       Willets Point|   47|\n",
      "|Forest Park/Highl...|   53|\n",
      "|  Brooklyn Navy Yard|   57|\n",
      "|        Crotona Park|   62|\n",
      "|        Country Club|   77|\n",
      "|     Freshkills Park|   89|\n",
      "|       Prospect Park|   98|\n",
      "|     Columbia Street|  105|\n",
      "|  South Williamsburg|  110|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "zone_counts.orderBy(col(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e13b3-b7e5-4c33-90d1-7d1b38636dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
